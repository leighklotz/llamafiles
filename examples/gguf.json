{"filename": "/home/klotz/wip/oobabooga/text-generation-webui/models/dolphin-2.7-mixtral-8x7b.Q4_K_M.gguf", "endian": "LITTLE", "metadata": {"GGUF.version": {"index": 0, "type": "UINT32", "offset": 4, "value": 3}, "GGUF.tensor_count": {"index": 1, "type": "UINT64", "offset": 8, "value": 995}, "GGUF.kv_count": {"index": 2, "type": "UINT64", "offset": 16, "value": 24}, "general.architecture": {"index": 3, "type": "STRING", "offset": 24, "value": "llama"}, "general.name": {"index": 4, "type": "STRING", "offset": 69, "value": "cognitivecomputations_dolphin-2.7-mixtral-8x7b"}, "llama.context_length": {"index": 5, "type": "UINT32", "offset": 147, "value": 32768}, "llama.embedding_length": {"index": 6, "type": "UINT32", "offset": 183, "value": 4096}, "llama.block_count": {"index": 7, "type": "UINT32", "offset": 221, "value": 32}, "llama.feed_forward_length": {"index": 8, "type": "UINT32", "offset": 254, "value": 14336}, "llama.rope.dimension_count": {"index": 9, "type": "UINT32", "offset": 295, "value": 128}, "llama.attention.head_count": {"index": 10, "type": "UINT32", "offset": 337, "value": 32}, "llama.attention.head_count_kv": {"index": 11, "type": "UINT32", "offset": 379, "value": 8}, "llama.expert_count": {"index": 12, "type": "UINT32", "offset": 424, "value": 8}, "llama.expert_used_count": {"index": 13, "type": "UINT32", "offset": 458, "value": 2}, "llama.attention.layer_norm_rms_epsilon": {"index": 14, "type": "FLOAT32", "offset": 497, "value": 9.999999747378752e-06}, "llama.rope.freq_base": {"index": 15, "type": "FLOAT32", "offset": 551, "value": 1000000.0}, "general.file_type": {"index": 16, "type": "UINT32", "offset": 587, "value": 15}, "tokenizer.ggml.model": {"index": 17, "type": "STRING", "offset": 620, "value": "llama"}, "tokenizer.ggml.tokens": {"index": 18, "type": "ARRAY", "offset": 665, "array_types": ["STRING"]}, "tokenizer.ggml.scores": {"index": 19, "type": "ARRAY", "offset": 461418, "array_types": ["FLOAT32"]}, "tokenizer.ggml.token_type": {"index": 20, "type": "ARRAY", "offset": 589471, "array_types": ["INT32"]}, "tokenizer.ggml.bos_token_id": {"index": 21, "type": "UINT32", "offset": 717528, "value": 1}, "tokenizer.ggml.eos_token_id": {"index": 22, "type": "UINT32", "offset": 717571, "value": 32000}, "tokenizer.ggml.add_bos_token": {"index": 23, "type": "BOOL", "offset": 717614, "value": true}, "tokenizer.ggml.add_eos_token": {"index": 24, "type": "BOOL", "offset": 717655, "value": false}, "tokenizer.chat_template": {"index": 25, "type": "STRING", "offset": 717696, "value": "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"}, "general.quantization_version": {"index": 26, "type": "UINT32", "offset": 718030, "value": 2}}, "tensors": {}}