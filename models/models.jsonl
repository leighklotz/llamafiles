codebooga-34b-v0.1.Q4_K_M.gguf
{"filename": "codebooga-34b-v0.1.Q4_K_M.gguf", "endian": "LITTLE", "metadata": {"GGUF.version": {"index": 0, "type": "UINT32", "offset": 4, "value": 3}, "GGUF.tensor_count": {"index": 1, "type": "UINT64", "offset": 8, "value": 435}, "GGUF.kv_count": {"index": 2, "type": "UINT64", "offset": 16, "value": 21}, "general.architecture": {"index": 3, "type": "STRING", "offset": 24, "value": "llama"}, "general.name": {"index": 4, "type": "STRING", "offset": 69, "value": "oobabooga_codebooga-34b-v0.1"}, "llama.context_length": {"index": 5, "type": "UINT32", "offset": 129, "value": 16384}, "llama.embedding_length": {"index": 6, "type": "UINT32", "offset": 165, "value": 8192}, "llama.block_count": {"index": 7, "type": "UINT32", "offset": 203, "value": 48}, "llama.feed_forward_length": {"index": 8, "type": "UINT32", "offset": 236, "value": 22016}, "llama.rope.dimension_count": {"index": 9, "type": "UINT32", "offset": 277, "value": 128}, "llama.attention.head_count": {"index": 10, "type": "UINT32", "offset": 319, "value": 64}, "llama.attention.head_count_kv": {"index": 11, "type": "UINT32", "offset": 361, "value": 8}, "llama.attention.layer_norm_rms_epsilon": {"index": 12, "type": "FLOAT32", "offset": 406, "value": 9.999999747378752e-06}, "llama.rope.freq_base": {"index": 13, "type": "FLOAT32", "offset": 460, "value": 1000000.0}, "general.file_type": {"index": 14, "type": "UINT32", "offset": 496, "value": 15}, "tokenizer.ggml.model": {"index": 15, "type": "STRING", "offset": 529, "value": "llama"}, "tokenizer.ggml.tokens": {"index": 16, "type": "ARRAY", "offset": 574, "array_types": ["STRING"]}, "tokenizer.ggml.scores": {"index": 17, "type": "ARRAY", "offset": 467538, "array_types": ["FLOAT32"]}, "tokenizer.ggml.token_type": {"index": 18, "type": "ARRAY", "offset": 595583, "array_types": ["INT32"]}, "tokenizer.ggml.bos_token_id": {"index": 19, "type": "UINT32", "offset": 723632, "value": 1}, "tokenizer.ggml.eos_token_id": {"index": 20, "type": "UINT32", "offset": 723675, "value": 2}, "tokenizer.ggml.unknown_token_id": {"index": 21, "type": "UINT32", "offset": 723718, "value": 0}, "tokenizer.ggml.padding_token_id": {"index": 22, "type": "UINT32", "offset": 723765, "value": 2}, "general.quantization_version": {"index": 23, "type": "UINT32", "offset": 723812, "value": 2}}, "tensors": {}} 
dolphin-2.7-mixtral-8x7b.Q4_K_M.gguf
{"filename": "dolphin-2.7-mixtral-8x7b.Q4_K_M.gguf", "endian": "LITTLE", "metadata": {"GGUF.version": {"index": 0, "type": "UINT32", "offset": 4, "value": 3}, "GGUF.tensor_count": {"index": 1, "type": "UINT64", "offset": 8, "value": 995}, "GGUF.kv_count": {"index": 2, "type": "UINT64", "offset": 16, "value": 24}, "general.architecture": {"index": 3, "type": "STRING", "offset": 24, "value": "llama"}, "general.name": {"index": 4, "type": "STRING", "offset": 69, "value": "cognitivecomputations_dolphin-2.7-mixtral-8x7b"}, "llama.context_length": {"index": 5, "type": "UINT32", "offset": 147, "value": 32768}, "llama.embedding_length": {"index": 6, "type": "UINT32", "offset": 183, "value": 4096}, "llama.block_count": {"index": 7, "type": "UINT32", "offset": 221, "value": 32}, "llama.feed_forward_length": {"index": 8, "type": "UINT32", "offset": 254, "value": 14336}, "llama.rope.dimension_count": {"index": 9, "type": "UINT32", "offset": 295, "value": 128}, "llama.attention.head_count": {"index": 10, "type": "UINT32", "offset": 337, "value": 32}, "llama.attention.head_count_kv": {"index": 11, "type": "UINT32", "offset": 379, "value": 8}, "llama.expert_count": {"index": 12, "type": "UINT32", "offset": 424, "value": 8}, "llama.expert_used_count": {"index": 13, "type": "UINT32", "offset": 458, "value": 2}, "llama.attention.layer_norm_rms_epsilon": {"index": 14, "type": "FLOAT32", "offset": 497, "value": 9.999999747378752e-06}, "llama.rope.freq_base": {"index": 15, "type": "FLOAT32", "offset": 551, "value": 1000000.0}, "general.file_type": {"index": 16, "type": "UINT32", "offset": 587, "value": 15}, "tokenizer.ggml.model": {"index": 17, "type": "STRING", "offset": 620, "value": "llama"}, "tokenizer.ggml.tokens": {"index": 18, "type": "ARRAY", "offset": 665, "array_types": ["STRING"]}, "tokenizer.ggml.scores": {"index": 19, "type": "ARRAY", "offset": 461418, "array_types": ["FLOAT32"]}, "tokenizer.ggml.token_type": {"index": 20, "type": "ARRAY", "offset": 589471, "array_types": ["INT32"]}, "tokenizer.ggml.bos_token_id": {"index": 21, "type": "UINT32", "offset": 717528, "value": 1}, "tokenizer.ggml.eos_token_id": {"index": 22, "type": "UINT32", "offset": 717571, "value": 32000}, "tokenizer.ggml.add_bos_token": {"index": 23, "type": "BOOL", "offset": 717614, "value": true}, "tokenizer.ggml.add_eos_token": {"index": 24, "type": "BOOL", "offset": 717655, "value": false}, "tokenizer.chat_template": {"index": 25, "type": "STRING", "offset": 717696, "value": "{% if not add_generation_prompt is defined %}{% set add_generation_prompt = false %}{% endif %}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n' + message['content'] + '<|im_end|>' + '\n'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n' }}{% endif %}"}, "general.quantization_version": {"index": 26, "type": "UINT32", "offset": 718030, "value": 2}}, "tensors": {}} 
mixtral_7bx2_moe.Q3_K_M.gguf
{"filename": "mixtral_7bx2_moe.Q3_K_M.gguf", "endian": "LITTLE", "metadata": {"GGUF.version": {"index": 0, "type": "UINT32", "offset": 4, "value": 3}, "GGUF.tensor_count": {"index": 1, "type": "UINT64", "offset": 8, "value": 419}, "GGUF.kv_count": {"index": 2, "type": "UINT64", "offset": 16, "value": 26}, "general.architecture": {"index": 3, "type": "STRING", "offset": 24, "value": "llama"}, "general.name": {"index": 4, "type": "STRING", "offset": 69, "value": "cloudyu_mixtral_7bx2_moe"}, "llama.context_length": {"index": 5, "type": "UINT32", "offset": 125, "value": 32768}, "llama.embedding_length": {"index": 6, "type": "UINT32", "offset": 161, "value": 4096}, "llama.block_count": {"index": 7, "type": "UINT32", "offset": 199, "value": 32}, "llama.feed_forward_length": {"index": 8, "type": "UINT32", "offset": 232, "value": 14336}, "llama.rope.dimension_count": {"index": 9, "type": "UINT32", "offset": 273, "value": 128}, "llama.attention.head_count": {"index": 10, "type": "UINT32", "offset": 315, "value": 32}, "llama.attention.head_count_kv": {"index": 11, "type": "UINT32", "offset": 357, "value": 8}, "llama.expert_count": {"index": 12, "type": "UINT32", "offset": 402, "value": 2}, "llama.expert_used_count": {"index": 13, "type": "UINT32", "offset": 436, "value": 2}, "llama.attention.layer_norm_rms_epsilon": {"index": 14, "type": "FLOAT32", "offset": 475, "value": 9.999999747378752e-06}, "llama.rope.freq_base": {"index": 15, "type": "FLOAT32", "offset": 529, "value": 10000.0}, "general.file_type": {"index": 16, "type": "UINT32", "offset": 565, "value": 12}, "tokenizer.ggml.model": {"index": 17, "type": "STRING", "offset": 598, "value": "llama"}, "tokenizer.ggml.tokens": {"index": 18, "type": "ARRAY", "offset": 643, "array_types": ["STRING"]}, "tokenizer.ggml.scores": {"index": 19, "type": "ARRAY", "offset": 461358, "array_types": ["FLOAT32"]}, "tokenizer.ggml.token_type": {"index": 20, "type": "ARRAY", "offset": 589403, "array_types": ["INT32"]}, "tokenizer.ggml.merges": {"index": 21, "type": "ARRAY", "offset": 717452, "array_types": ["STRING"]}, "tokenizer.ggml.bos_token_id": {"index": 22, "type": "UINT32", "offset": 1653772, "value": 1}, "tokenizer.ggml.eos_token_id": {"index": 23, "type": "UINT32", "offset": 1653815, "value": 2}, "tokenizer.ggml.unknown_token_id": {"index": 24, "type": "UINT32", "offset": 1653858, "value": 0}, "tokenizer.ggml.padding_token_id": {"index": 25, "type": "UINT32", "offset": 1653905, "value": 1}, "tokenizer.ggml.add_bos_token": {"index": 26, "type": "BOOL", "offset": 1653952, "value": true}, "tokenizer.ggml.add_eos_token": {"index": 27, "type": "BOOL", "offset": 1653993, "value": false}, "general.quantization_version": {"index": 28, "type": "UINT32", "offset": 1654034, "value": 2}}, "tensors": {}} 
rocket-3b.Q6_K.gguf
{"filename": "rocket-3b.Q6_K.gguf", "endian": "LITTLE", "metadata": {"GGUF.version": {"index": 0, "type": "UINT32", "offset": 4, "value": 3}, "GGUF.tensor_count": {"index": 1, "type": "UINT64", "offset": 8, "value": 356}, "GGUF.kv_count": {"index": 2, "type": "UINT64", "offset": 16, "value": 19}, "general.architecture": {"index": 3, "type": "STRING", "offset": 24, "value": "stablelm"}, "general.name": {"index": 4, "type": "STRING", "offset": 72, "value": "source"}, "stablelm.context_length": {"index": 5, "type": "UINT32", "offset": 110, "value": 4096}, "stablelm.embedding_length": {"index": 6, "type": "UINT32", "offset": 149, "value": 2560}, "stablelm.block_count": {"index": 7, "type": "UINT32", "offset": 190, "value": 32}, "stablelm.feed_forward_length": {"index": 8, "type": "UINT32", "offset": 226, "value": 6912}, "stablelm.rope.dimension_count": {"index": 9, "type": "UINT32", "offset": 270, "value": 20}, "stablelm.attention.head_count": {"index": 10, "type": "UINT32", "offset": 315, "value": 32}, "stablelm.use_parallel_residual": {"index": 11, "type": "BOOL", "offset": 360, "value": true}, "stablelm.attention.layer_norm_epsilon": {"index": 12, "type": "FLOAT32", "offset": 403, "value": 9.999999747378752e-06}, "tokenizer.ggml.model": {"index": 13, "type": "STRING", "offset": 456, "value": "gpt2"}, "tokenizer.ggml.tokens": {"index": 14, "type": "ARRAY", "offset": 500, "array_types": ["STRING"]}, "tokenizer.ggml.token_type": {"index": 15, "type": "ARRAY", "offset": 760527, "array_types": ["INT32"]}, "tokenizer.ggml.merges": {"index": 16, "type": "ARRAY", "offset": 961792, "array_types": ["STRING"]}, "tokenizer.ggml.bos_token_id": {"index": 17, "type": "UINT32", "offset": 1768484, "value": 0}, "tokenizer.ggml.unknown_token_id": {"index": 18, "type": "UINT32", "offset": 1768527, "value": 0}, "tokenizer.ggml.eos_token_id": {"index": 19, "type": "UINT32", "offset": 1768574, "value": 50279}, "general.quantization_version": {"index": 20, "type": "UINT32", "offset": 1768617, "value": 2}, "general.file_type": {"index": 21, "type": "UINT32", "offset": 1768661, "value": 18}}, "tensors": {}} 
