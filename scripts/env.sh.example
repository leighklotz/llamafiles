# include-once
if [ -z "${IN_LLM_SH_ENV}" ]; then
IN_LLM_SH_ENV=1

# These are the variables you can set in ./env.sh or in the environment
# If you don't want these to override current env,
# use the bash ":-" variable parameter as in TEMPERATURE=${TEMPERATURE:-0.1}

# DEBUG=
# ERROR_OUTPUT=
# GRAMMAR_FILE=
# KEEP_PROMPT_TEMP_FILE=
# LLM_ADDITIONAL_ARGS=
# LOG_DISABLE=
# N_PREDICT=
# PRINT_STACK_TRACE=
# SCUTTLE_REFERER
# SCUTTLE_USER_AGENT=
# SILENT_PROMPT=
# SUMMARIZE_USER_AGENT=
# USE_SYSTEM_ROLE=
# SYSTEM_MESSAGE=
# TEMPERATURE=
# VERBOSE=
# USE_GRAMMAR=
# VIA_API_CHAT_BASE=

KEEP_PROMPT_TEMP_FILE="${KEEP_PROMPT_TEMP_FILE:-ERRORS}"
PRINT_STACK_TRACE="${PRINT_STACK_TRACE:-1}"

# Known host and known network configs
if [ -n "$VIA_API_CHAT_BASE" ];
then
    true
elif [ "${HOSTNAME}" == "tensor" ];
then
    export VIA_API_CHAT_BASE="${VIA_API_CHAT_BASE:-http://localhost:5000}"
elif ${SCRIPT_DIR}/onsubnet.sh 192\.168\.1\. ;
then
    export VIA_API_CHAT_BASE="${VIA_API_CHAT_BASE:-http://tensor-net.example.com:5000}"
elif ${SCRIPT_DIR}/onsubnet.sh 10\.0\.0\. ;
then
    export VIA_API_CHAT_BASE="${VIA_API_CHAT_BASE:-http://tensor.example.com:5000}"
fi

unset IN_LLM_SH_ENV
fi
